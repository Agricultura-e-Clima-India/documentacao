# üìÑ Documenta√ß√£o de Participa√ß√£o do Projeto de Pipeline de Dados

**FACULDADE DONADUZZI**
**BIOPARK EDUCA√á√ÉO - 1¬∫ PER√çODO CD e Al**

Com o objetivo de documentar e esclarecer a elabora√ß√£o do nosso projeto aplicado, desenvolvido para a disciplina de **Pipeline de dados**, apresentamos este detalhamento das contribui√ß√µes. Este registro serve para garantir a transpar√™ncia e o reconhecimento do esfor√ßo de toda a equipe no resultado final.

---

## üìÖ Informa√ß√µes Essenciais

* **Trabalho:** Pipeline de dados
* **Orientador:** Wesley Antonio Santos de Andrade Sobreira
* **Data de Refer√™ncia:** 27 de novembro de 2025
* **Local:** Toledo, Paran√°

---

## üë• Membros do Grupo

1.  **Braian Cauan Marqueto**
2.  **Jo√£o H√©lio dos Santos Glinski**
3.  **Luiz Henrique Zavatini Feltrin**
4.  **Marco Antonio Wandraski**

---




As se√ß√µes a seguir especificam o papel de cada integrante, as responsabilidades principais e as etapas do projeto que foram executadas individualmente.

### 1. Braian Cauan Marqueto

| Categoria | Detalhes |
| :--- | :--- |
| **Fun√ß√£o Principal** | **Especialista Postgres** |
| **Atividades Realizadas** | * Configura√ß√£o de adapta√ß√£o de **SQLite para Postgres**.<br>* Desenvolvimento de testes local e nuvem do carregamento dos dados.<br>* Funcionalidades de vari√°veis do Postgres. |
| **Arquivos Modificados** | `database.py` (modificado), `05_create_database_pg_schema.ipynb` (modificado), `06_load_to_postgres.ipynb` (modificado), `05_create_database_pg_schema_spark.ipynb` (modificado), `06_load_to_postgres_spark.ipynb` (modificado), `config.py` (modificado). |

### 2. Jo√£o H√©lio dos Santos Glinski

| Categoria | Detalhes |
| :--- | :--- |
| **Fun√ß√£o Principal** | **Analista de Suporte e Estrutura√ß√£o T√©cnica** |
| **Atividades Realizadas** | * **Refatora√ß√£o e migra√ß√£o dos scripts** de processamento de Pandas para **Apache Spark (PySpark)**.<br>* Idealizador e Editor do **v√≠deo de apresenta√ß√£o**.<br>* Documenta√ß√£o de participa√ß√£o do grupo.|
| **Arquivos Criados/Modificados** | **Fase 3:** `Spark_Pipeline.ipynb`<br>**Fase 4:** `participacao.md`<br>**Fase 4:** `Pipeline.mp4`

### 3. Luiz Henrique Zavatini Feltrin

| Categoria | Detalhes |
| :--- | :--- |
| **Fun√ß√£o Principal** | **Engenheiro de Dados & Infraestrutura (DevOps & Orquestra√ß√£o)** |
| **Atividades Realizadas** | * **Explora√ß√£o inicial de dados** e defini√ß√£o do dataset base (**Agricultura e Clima**).<br>* Estrutura√ß√£o da camada de persist√™ncia e scripts de carga para **PostgreSQL**.<br>* Configura√ß√£o de ambiente e **containeriza√ß√£o com Docker e Docker Compose**.<br>* Desenvolvimento e manuten√ß√£o da **DAG de orquestra√ß√£o no Apache Airflow**.<br>* Cria√ß√£o e implementa√ß√£o de m√≥dulos de **utilit√°rios de banco de dados (`db_utils`), valida√ß√£o de dados e monitoramento do pipeline**.<br>* Gerenciamento de credenciais e configura√ß√µes de ambiente. |
| **Arquivos Relevantes** | **Fase 01 (Explora√ß√£o):** `pipeline.ipynb` (Google Colab)<br>**Fase 03 (Postgres):** `database.py` (criado), `SQL_queries.ipynb` (criado), `06_load_to_postgres.ipynb` (criado), edi√ß√µes em arquivos de *layers* e *data quality*<br>**Fase 04 (Infra/Airflow):** `Dockerfile` (criado), `docker-compose.yaml` (editado), `monitoring.py` (criado), `validate.py` (criado), `db_utils.py` (criado), `pipeline_agricultura_dag.py` (editado)<br>**Fase 04 (Spark Jobs):** Edi√ß√µes em todos os *Spark Jobs* (`bronze.py`, `silver.py`, `gold.py`, `load_to_postgres.py`, `spark_session_manager.py`) |

### 4. Marco Antonio Wandraski

| Categoria | Detalhes |
| :--- | :--- |
| **Fun√ß√£o Principal** | **Engenheiro de Dados Full Cycle & Documenta√ß√£o T√©cnica** |
| **Atividades Realizadas** | * Defini√ß√£o t√©cnica e documenta√ß√£o da proposta inicial e requisitos.<br>* **Desenvolvimento integral do Pipeline ETL (Fase 02)** com ingest√£o e refinamento.<br>* An√°lise estat√≠stica, detec√ß√£o e tratamento de **outliers/anomalias**.<br>* Fundamenta√ß√£o te√≥rica e documenta√ß√£o da **Arquitetura Medallion** (Bronze, Silver, Gold). <br>* **Refatora√ß√£o e migra√ß√£o dos scripts** de Pandas para **Apache Spark (PySpark)**.<br>* **Co-desenvolvimento e implementa√ß√£o da orquestra√ß√£o** do pipeline via **Apache Airflow**.<br>* Elabora√ß√£o de documenta√ß√£o do projeto e guias de funcionamento. |
| **Arquivos Relevantes** | **Fase 02 (ETL Inicial):** Cria√ß√£o dos notebooks de layers (`#bronze_layer.ipynb`, `#silver_layer.ipynb`, `#gold_layer.ipynb`), `data_quality_report.ipynb` (criado), `load_to_database.ipynb` (criado)<br>**Fase 03 (Migra√ß√£o Spark):** Cria√ß√£o de todos os notebooks Spark (`00_setup_spark_parquet.ipynb` a `06_load_to_postgres_spark.ipynb`), `SQL_queries_spark.ipynb` (criado)<br>**Fase 04 (Documenta√ß√£o):** `Documenta√ß√£o-completa.md`<br>**Outros:** Link para Arquivos iniciais Airflow: `https://encurtador.com.br/gshn` |

---